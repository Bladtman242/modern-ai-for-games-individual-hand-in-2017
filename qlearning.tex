\section{Agent: Temporal Difference Learning with Q-Learning}
\label{sec:qlearning}
I tried two approaches for training an agent with temporal difference learning.
First, I simply tried training the agent by letting it play Ms. Pac-Man,
adjusting expectations according to actual game scores. Then I tried training it
by giving it a high reward for actions that the GA agent would have picked in the
same state, and low rewards for different actions. Neither of these approaches
where particularly successful.


\textbf{TODO:} rest of the sections/details on qlearning.
\subsection{Description of Approach (e.g. input, output, action, state space,
representation)}

\subsection{Algorithm Parameters:}

\subsection{Which parameters needed to be adjusted (e.g. ANN learning rate),
which were picked by default (e.g. connection weight interval) and why?}

\subsection{What was the experiment followed to adjust those parameters of the
algorithm.}

\subsection{Performance measure of the algorithm}

\subsection{Experiments (My player against the provided Ô¨Åxed-players)}
Conclusions (Why did it work? Why it didn't work? If it didn't work as expected what could you suggest that it has to be changed for the algorithm to work and why didn't you try it?)
